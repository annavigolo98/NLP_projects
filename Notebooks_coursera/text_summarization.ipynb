{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM \n",
    "from transformers import AutoTokenizer \n",
    "from transformers import GenerationConfig \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TASK: Text summarization.\n",
    "#Dataset loading \n",
    "\n",
    "dataset_name = 'knkarthick/dialogsum'\n",
    "dataset = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "    num_rows: 12460\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "    num_rows: 1500\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1\n",
      "Dialogue \n",
      "\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "#Person1#: Ms. Dawson, I need you to take a dictation for me.\n",
      "#Person2#: Yes, sir...\n",
      "#Person1#: This should go out as an intra-office memorandum to all employees by this afternoon. Are you ready?\n",
      "#Person2#: Yes, sir. Go ahead.\n",
      "#Person1#: Attention all staff... Effective immediately, all office communications are restricted to email correspondence and official memos. The use of Instant Message programs by employees during working hours is strictly prohibited.\n",
      "#Person2#: Sir, does this apply to intra-office communications only? Or will it also restrict external communications?\n",
      "#Person1#: It should apply to all communications, not only in this office between employees, but also any outside communications.\n",
      "#Person2#: But sir, many employees use Instant Messaging to communicate with their clients.\n",
      "#Person1#: They will just have to change their communication methods. I don't want any - one using Instant Messaging in this office. It wastes too much time! Now, please continue with the memo. Where were we?\n",
      "#Person2#: This applies to internal and external communications.\n",
      "#Person1#: Yes. Any employee who persists in using Instant Messaging will first receive a warning and be placed on probation. At second offense, the employee will face termination. Any questions regarding this new policy may be directed to department heads.\n",
      "#Person2#: Is that all?\n",
      "#Person1#: Yes. Please get this memo typed up and distributed to all employees before 4 pm.\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Summary \n",
      "\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Ms. Dawson helps #Person1# to write a memo to inform every employee that they have to change the communication method and should not use Instant Messaging anymore.\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Example 2\n",
      "Dialogue \n",
      "\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "#Person1#: Ms. Dawson, I need you to take a dictation for me.\n",
      "#Person2#: Yes, sir...\n",
      "#Person1#: This should go out as an intra-office memorandum to all employees by this afternoon. Are you ready?\n",
      "#Person2#: Yes, sir. Go ahead.\n",
      "#Person1#: Attention all staff... Effective immediately, all office communications are restricted to email correspondence and official memos. The use of Instant Message programs by employees during working hours is strictly prohibited.\n",
      "#Person2#: Sir, does this apply to intra-office communications only? Or will it also restrict external communications?\n",
      "#Person1#: It should apply to all communications, not only in this office between employees, but also any outside communications.\n",
      "#Person2#: But sir, many employees use Instant Messaging to communicate with their clients.\n",
      "#Person1#: They will just have to change their communication methods. I don't want any - one using Instant Messaging in this office. It wastes too much time! Now, please continue with the memo. Where were we?\n",
      "#Person2#: This applies to internal and external communications.\n",
      "#Person1#: Yes. Any employee who persists in using Instant Messaging will first receive a warning and be placed on probation. At second offense, the employee will face termination. Any questions regarding this new policy may be directed to department heads.\n",
      "#Person2#: Is that all?\n",
      "#Person1#: Yes. Please get this memo typed up and distributed to all employees before 4 pm.\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Summary \n",
      "\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Ms. Dawson takes a dictation for #Person1# about prohibiting the use of Instant Message programs in the office. They argue about its reasonability but #Person1# still insists.\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n"
     ]
    }
   ],
   "source": [
    "dash_line = '-'.join(' ' for x in range(50)) #Create 50 spaces joined by '-' character.\n",
    "dash_line\n",
    "\n",
    "example_idxs = [0, 2]\n",
    "for i, idx in enumerate(example_idxs):\n",
    "    print(f'Example {1+i}')\n",
    "    print('Dialogue \\n')\n",
    "    print(dash_line)\n",
    "    print(dataset['test'][idx]['dialogue'])\n",
    "    print(dash_line)\n",
    "    print('Summary \\n')\n",
    "    print(dash_line)\n",
    "    print(dataset['test'][idx]['summary'])\n",
    "    print(dash_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 'google/flan-t5-base'\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, usefast=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8774,    6,  149,   33,   25,   58,    1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello, how are you?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'Hello, how are you?'\n",
    "tokenized_sentence = tokenizer(sentence, return_tensors='pt')\n",
    "print(tokenized_sentence['input_ids'][0])\n",
    "tokenizer.decode(tokenized_sentence['input_ids'][0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n",
      "tensor([  283,     7,     5, 31676,  1691,  1713,   345, 13515,   536,  4663,\n",
      "           12,  1431,     3,     9, 22986,    12,  3261,   334,  3490,    24,\n",
      "           79,    43,    12,   483,     8,  1901,  1573,    11,   225,    59,\n",
      "          169, 18882,  6598,  5855,  7595,     5,     1,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Ms. Dawson takes a dictation for #Person1# about prohibiting the use of Instant Message programs in the office. They argue about its reasonability but #Person1# still insists.\n"
     ]
    }
   ],
   "source": [
    "sentence = 'Hello world'\n",
    "tokenizer.tokenize(sentence)\n",
    "print(sentence)\n",
    "batch = dataset['test'][:4]\n",
    "encoded_sentence = tokenizer(batch['summary'], return_tensors='pt', truncation=True, padding=True) \n",
    "# For handling a batch returning tensors give errors\n",
    "# Truncation and padding solve this problem\n",
    "# One possible solution to handle batches is to use the DataCollator or tokenizer itself, which handles by itself the \n",
    "# padding and the conversion to tensors. Used later for model fine tuning in lazy-programmer course\n",
    "\n",
    "print(encoded_sentence['input_ids'][0]) # See the first sentence\n",
    "decoded_sentence = tokenizer.decode(encoded_sentence['input_ids'][2], skip_special_tokens=True)\n",
    "print(decoded_sentence) # See the first decoded sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue:  #Person1#: What time is it, Tom?\n",
      "#Person2#: Just a minute. It's ten to nine by my watch.\n",
      "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
      "#Person2#: What's the hurry?\n",
      "#Person1#: I must catch the nine-thirty train.\n",
      "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there. \n",
      "\n",
      "Decoded summary:  Person1: It's ten to nine. \n",
      "\n",
      "Target summary:  #Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time. \n",
      "\n",
      "Dialogue:  #Person1#: What time is it, Tom?\n",
      "#Person2#: Just a minute. It's ten to nine by my watch.\n",
      "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
      "#Person2#: What's the hurry?\n",
      "#Person1#: I must catch the nine-thirty train.\n",
      "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there. \n",
      "\n",
      "Decoded summary:  Person1: It's ten to nine. \n",
      "\n",
      "Target summary:  #Person1# is rushing to catch a train but Tom thinks it isn't necessary. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_idxs = [40,41]\n",
    "\n",
    "for i, idx in enumerate(example_idxs):\n",
    "    tokenized_dialogue = tokenizer(dataset['test'][idx]['dialogue'], return_tensors='pt')\n",
    "    #print(tokenized_dialogue['input_ids'][0])\n",
    "    decoded_summary = tokenizer.decode(\n",
    "        model.generate(tokenized_dialogue['input_ids'], max_new_tokens=50)[0],\n",
    "        skip_special_tokens=True)  \n",
    "    # This handles a batch of data (tokenized_dialogue['input_ids'])\n",
    "    # This also returns a tuple and we have to take the [0]th element to obtain the summary to decode\n",
    "    \n",
    "\n",
    "    print('Dialogue: ', dataset['test'][idx]['dialogue'], '\\n')\n",
    "    print('Decoded summary: ',decoded_summary, '\\n')\n",
    "    print('Target summary: ', dataset['test'][idx]['summary'], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:  \n",
      "Summarize the following conversation.\n",
      "#Person1#: What time is it, Tom?\n",
      "#Person2#: Just a minute. It's ten to nine by my watch.\n",
      "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
      "#Person2#: What's the hurry?\n",
      "#Person1#: I must catch the nine-thirty train.\n",
      "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
      "\n",
      "Summary:\n",
      "     \n",
      "\n",
      "Target summary:  #Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time. \n",
      "\n",
      "Model summary:  The train is about to leave. \n",
      "\n",
      "Prompt:  \n",
      "Summarize the following conversation.\n",
      "#Person1#: What time is it, Tom?\n",
      "#Person2#: Just a minute. It's ten to nine by my watch.\n",
      "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
      "#Person2#: What's the hurry?\n",
      "#Person1#: I must catch the nine-thirty train.\n",
      "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
      "\n",
      "Summary:\n",
      "     \n",
      "\n",
      "Target summary:  #Person1# is rushing to catch a train but Tom thinks it isn't necessary. \n",
      "\n",
      "Model summary:  The train is about to leave. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_idxs = [40,41]\n",
    "\n",
    "for i, idx in enumerate(example_idxs):\n",
    "    dialogue = dataset['test'][idx]['dialogue']\n",
    "    summary = dataset['test'][idx]['summary']\n",
    "    prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "{dialogue}\n",
    "\n",
    "Summary:\n",
    "    \"\"\"\n",
    "    tokenized_dialogue = tokenizer(prompt, return_tensors='pt')\n",
    "    m_summary = tokenizer.decode(\n",
    "        model.generate(tokenized_dialogue['input_ids'], max_new_tokens=50)[0],\n",
    "        skip_special_tokens = True\n",
    "        )\n",
    "    print('Prompt: ', prompt, '\\n')\n",
    "    \n",
    "    print('Target summary: ', summary, '\\n')\n",
    "\n",
    "    print('Model summary: ', m_summary, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:  \n",
      "Dialogue:\n",
      "#Person1#: What time is it, Tom?\n",
      "#Person2#: Just a minute. It's ten to nine by my watch.\n",
      "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
      "#Person2#: What's the hurry?\n",
      "#Person1#: I must catch the nine-thirty train.\n",
      "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
      "\n",
      "What is going on?\n",
      "     \n",
      "\n",
      "Target summary:  #Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time. \n",
      "\n",
      "Model summary:  Tom is late for the train. \n",
      "\n",
      "Prompt:  \n",
      "Dialogue:\n",
      "#Person1#: What time is it, Tom?\n",
      "#Person2#: Just a minute. It's ten to nine by my watch.\n",
      "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
      "#Person2#: What's the hurry?\n",
      "#Person1#: I must catch the nine-thirty train.\n",
      "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
      "\n",
      "What is going on?\n",
      "     \n",
      "\n",
      "Target summary:  #Person1# is rushing to catch a train but Tom thinks it isn't necessary. \n",
      "\n",
      "Model summary:  Tom is late for the train. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_idxs = [40,41]\n",
    "\n",
    "for i, idx in enumerate(example_idxs):\n",
    "    dialogue = dataset['test'][idx]['dialogue']\n",
    "    summary = dataset['test'][idx]['summary']\n",
    "    prompt = f\"\"\"\n",
    "Dialogue:\n",
    "{dialogue}\n",
    "\n",
    "What is going on?\n",
    "    \"\"\"\n",
    "    tokenized_dialogue = tokenizer(prompt, return_tensors='pt')\n",
    "    m_summary = tokenizer.decode(\n",
    "        model.generate(tokenized_dialogue['input_ids'], max_new_tokens=50)[0],\n",
    "        skip_special_tokens = True\n",
    "        )\n",
    "    print('Prompt: ', prompt, '\\n')\n",
    "    \n",
    "    print('Target summary: ', summary, '\\n')\n",
    "\n",
    "    print('Model summary: ', m_summary, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(all_indices, index):\n",
    "    prompt = ''\n",
    "    for i, idx in enumerate(all_indices):\n",
    "        dialogue = dataset['test'][idx]['dialogue']\n",
    "        summary = dataset['test'][idx]['summary']\n",
    "        prompt+= f\"\"\"\n",
    "                Dialogue: {dialogue}\n",
    "\n",
    "                What's going on? {summary}\n",
    "        \"\"\"\n",
    "    selected_dialogue = dataset['test'][index]['dialogue']\n",
    "    prompt+=f\"\"\"\n",
    "                Dialogue: {selected_dialogue}\n",
    "\n",
    "                What's going on?\n",
    "        \"\"\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                Dialogue: #Person1#: Would you like to go to the party tonight?\n",
      "#Person2#: Whose party?\n",
      "#Person1#: Ruojia's. Don't you know that? Ruojia has got married.\n",
      "#Person2#: What! Is she really? I can't believe it!\n",
      "#Person1#: Yes. Yesterday.\n",
      "#Person2#: Good gracious. That's incredible! I feel so happy for her!\n",
      "#Person1#: Yes, me too.\n",
      "#Person2#: But how do you know that?\n",
      "#Person1#: I saw the news from her twitter. And she sent an email about it.\n",
      "#Person2#: What? I didn't receive it!\n",
      "#Person1#: Maybe you should check your email.\n",
      "#Person2#: Oh yes, I find it. Tonight at her home. Will you bring something?\n",
      "#Person1#: Yes, a pair of wineglasses and a card to wish her happy marriage.\n",
      "#Person2#: I will buy a tea set.\n",
      "\n",
      "                What's going on? #Person1# tells #Person2# that Ruojia is married and will have a party tonight. #Person2#'s surprised to know that. They will bring their gifts to bless her.\n",
      "        \n",
      "                Dialogue: #Person1#: Would you like to go to the party tonight?\n",
      "#Person2#: Whose party?\n",
      "#Person1#: Ruojia's. Don't you know that? Ruojia has got married.\n",
      "#Person2#: What! Is she really? I can't believe it!\n",
      "#Person1#: Yes. Yesterday.\n",
      "#Person2#: Good gracious. That's incredible! I feel so happy for her!\n",
      "#Person1#: Yes, me too.\n",
      "#Person2#: But how do you know that?\n",
      "#Person1#: I saw the news from her twitter. And she sent an email about it.\n",
      "#Person2#: What? I didn't receive it!\n",
      "#Person1#: Maybe you should check your email.\n",
      "#Person2#: Oh yes, I find it. Tonight at her home. Will you bring something?\n",
      "#Person1#: Yes, a pair of wineglasses and a card to wish her happy marriage.\n",
      "#Person2#: I will buy a tea set.\n",
      "\n",
      "                What's going on?\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "#ONE SHOT EXAMPLE \n",
    "\n",
    "example_idxs = [45]\n",
    "selected_index = 46\n",
    "one_shot_prompt = make_prompt(example_idxs, selected_index)\n",
    "print(one_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated_summary:  #Person1 tells #Person2# that Ruojia is married and will have a party tonight. #Person1 tells #Person2# that Ruojia is married and will have a party tonight.\n",
      "Target_summary:  #Person2# is surprised to know from #Person1# that Ruojia is married. Then #Person2# finds Ruojia has sent an email about it. They will go to Ruojia's party and give their presents to her.\n"
     ]
    }
   ],
   "source": [
    "tokenized_input = tokenizer(one_shot_prompt, return_tensors='pt')\n",
    "generated_summary = tokenizer.decode(\n",
    "    model.generate(tokenized_input['input_ids'], max_new_tokens=50)[0],\n",
    "      skip_special_tokens=True)\n",
    "print('Generated_summary: ', generated_summary)\n",
    "print('Target_summary: ', dataset['test'][selected_index]['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                Dialogue: #Person1#: Would you like to go to the party tonight?\n",
      "#Person2#: Whose party?\n",
      "#Person1#: Ruojia's. Don't you know that? Ruojia has got married.\n",
      "#Person2#: What! Is she really? I can't believe it!\n",
      "#Person1#: Yes. Yesterday.\n",
      "#Person2#: Good gracious. That's incredible! I feel so happy for her!\n",
      "#Person1#: Yes, me too.\n",
      "#Person2#: But how do you know that?\n",
      "#Person1#: I saw the news from her twitter. And she sent an email about it.\n",
      "#Person2#: What? I didn't receive it!\n",
      "#Person1#: Maybe you should check your email.\n",
      "#Person2#: Oh yes, I find it. Tonight at her home. Will you bring something?\n",
      "#Person1#: Yes, a pair of wineglasses and a card to wish her happy marriage.\n",
      "#Person2#: I will buy a tea set.\n",
      "\n",
      "                What's going on? #Person1# tells #Person2# that Ruojia is married and will have a party tonight. #Person2#'s surprised to know that. They will bring their gifts to bless her.\n",
      "        \n",
      "                Dialogue: #Person1#: Would you like to go to the party tonight?\n",
      "#Person2#: Whose party?\n",
      "#Person1#: Ruojia's. Don't you know that? Ruojia has got married.\n",
      "#Person2#: What! Is she really? I can't believe it!\n",
      "#Person1#: Yes. Yesterday.\n",
      "#Person2#: Good gracious. That's incredible! I feel so happy for her!\n",
      "#Person1#: Yes, me too.\n",
      "#Person2#: But how do you know that?\n",
      "#Person1#: I saw the news from her twitter. And she sent an email about it.\n",
      "#Person2#: What? I didn't receive it!\n",
      "#Person1#: Maybe you should check your email.\n",
      "#Person2#: Oh yes, I find it. Tonight at her home. Will you bring something?\n",
      "#Person1#: Yes, a pair of wineglasses and a card to wish her happy marriage.\n",
      "#Person2#: I will buy a tea set.\n",
      "\n",
      "                What's going on? #Person2# is surprised to know from #Person1# that Ruojia is married. Then #Person2# finds Ruojia has sent an email about it. They will go to Ruojia's party and give their presents to her.\n",
      "        \n",
      "                Dialogue: #Person1#: Would you like to go to the party tonight?\n",
      "#Person2#: Whose party?\n",
      "#Person1#: Ruojia's. Don't you know that? Ruojia has got married.\n",
      "#Person2#: What! Is she really? I can't believe it!\n",
      "#Person1#: Yes. Yesterday.\n",
      "#Person2#: Good gracious. That's incredible! I feel so happy for her!\n",
      "#Person1#: Yes, me too.\n",
      "#Person2#: But how do you know that?\n",
      "#Person1#: I saw the news from her twitter. And she sent an email about it.\n",
      "#Person2#: What? I didn't receive it!\n",
      "#Person1#: Maybe you should check your email.\n",
      "#Person2#: Oh yes, I find it. Tonight at her home. Will you bring something?\n",
      "#Person1#: Yes, a pair of wineglasses and a card to wish her happy marriage.\n",
      "#Person2#: I will buy a tea set.\n",
      "\n",
      "                What's going on? #Person2# is surprised that Ruojia's married. #Person1# and #Person2# will go to her party and give their presents to wish her a happy marriage.\n",
      "        \n",
      "                Dialogue: #Person1#: Yeah. Just pull on this strip. Then peel off the back.\n",
      "#Person2#: You might make a few enemies this way.\n",
      "#Person1#: If they don't think this is fun, they're not meant to be our friends.\n",
      "#Person2#: You mean your friends. I think it's cruel.\n",
      "#Person1#: Yeah. But it's fun. Look at those two ugly old ladies. . . or are they men?\n",
      "#Person2#: Hurry! Get a shot!. . . Hand it over!\n",
      "#Person1#: I knew you'd come around. . .\n",
      "\n",
      "                What's going on?\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "example_idxs = [45, 46, 47]\n",
    "selected_index = 48\n",
    "few_shot_prompt = make_prompt(example_idxs, selected_index)\n",
    "print(few_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated_summary:  #Person1: You're a good friend.\n",
      "Target_summary:  #Person2# at first thinks #Person1#'s behaviour cruel but finally joins #Person1#.\n"
     ]
    }
   ],
   "source": [
    "tokenized_input = tokenizer(few_shot_prompt, return_tensors='pt')\n",
    "generated_summary = tokenizer.decode(\n",
    "    model.generate(tokenized_input['input_ids'], max_new_tokens=50)[0],\n",
    "      skip_special_tokens=True)\n",
    "print('Generated_summary: ', generated_summary)\n",
    "print('Target_summary: ', dataset['test'][selected_index]['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated_summary:  #Person1: You're a good friend.\n",
      "Target_summary:  #Person2# at first thinks #Person1#'s behaviour cruel but finally joins #Person1#.\n"
     ]
    }
   ],
   "source": [
    "generation_config = GenerationConfig(max_new_tokens=70, do_sample=True, temperature=0.2, top_p=0.5)\n",
    "\n",
    "tokenized_input = tokenizer(few_shot_prompt, return_tensors='pt')\n",
    "generated_summary = tokenizer.decode(\n",
    "    model.generate(tokenized_input['input_ids'], generation_config=generation_config)[0],\n",
    "      skip_special_tokens=True)\n",
    "print('Generated_summary: ', generated_summary)\n",
    "print('Target_summary: ', dataset['test'][selected_index]['summary'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
